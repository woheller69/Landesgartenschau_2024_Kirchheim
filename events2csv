import requests
from bs4 import BeautifulSoup
import csv

# Base URL without pagination parameters
base_url = "https://veranstaltungen.kirchheim2024.de/region/?suche&datum1=2024-05-20&datum2=2024-05-20"
# Define headers to mimic a browser request
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Referer': 'https://veranstaltungen.kirchheim2024.de/'
}

# Create a session object to handle cookies
session = requests.Session()
session.headers.update(headers)

events = []
os_value = 0
events_found = True

while events_found:
    # Construct the URL with pagination parameters
    url = f"{base_url}&os={os_value}&send=foo"
    
    # Fetch the HTML content from the URL
    response = session.get(url)
    
    # Check for successful request
    if response.status_code == 200:
        html_content = response.content

        # Parse the HTML content using BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')

        # Find all event blocks
        event_blocks = soup.find_all('div', class_='eventlist_row')

        if not event_blocks:
            events_found = False
            break

        for block in event_blocks:
            # Extract the title
            title_tag = block.find('h2')
            title = title_tag.text.strip() if title_tag else "No title found"

            # Extract the link
            link_tag = title_tag.find('a') if title_tag else None
            link = link_tag['href'] if link_tag else "No link found"

            # Extract the datetime and split into place, date and time
            datetime_tag = block.find('span', class_='datetime')
            if datetime_tag:
                datetime_parts = datetime_tag.text.strip().split('|')
                place = datetime_parts[0].strip() if len(datetime_parts) > 0 else "No place found"
                date = datetime_parts[1].strip() if len(datetime_parts) > 1 else "No date found"
                time = datetime_parts[2].strip() if len(datetime_parts) > 2 else "Ganztägig"
            else:
                place = "No place found"
                date = "No date found"
                time = "Ganztägig"

            # Extract the category
            category_tag = block.find('span', class_='kategorie')
            if category_tag:
                category_img = category_tag.find('img')
                category = category_img['title'] if category_img else "No category found"
            else:
                category = "No category found"

            # Extract the event text
            event_text_tag = block.find('div', class_='event-text')
            event_text = event_text_tag.text.strip() if event_text_tag else "No event text found"
            if event_text.endswith("mehr"):
                event_text = event_text[:-4].strip()

            # Store the data in a dictionary
            event = {
                'title': title.replace('\n', ' '),
                'link': link,
                'place': place.replace('\n', ' '),
                'date': date.replace('\n', ' '),
                'time': time.replace('\n', ' '),
                'category': category.replace('\n', ' '),
                'event_text': event_text.replace('\n', ' ')
            }

            # Add the dictionary to the list
            events.append(event)

        # Increment the os_value for the next page
        os_value += 25
        print(os_value)

    else:
        print(f"Failed to fetch page. Status code: {response.status_code}")
        break

# Save the list of events to a CSV file with ~ as the separator
csv_file = 'events.csv'
csv_columns = ['date', 'time', 'title', 'place', 'category', 'event_text', 'link']

try:
    with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter='~')
        writer.writeheader()
        for event in events:
            writer.writerow(event)
    print("Events data has been saved to events.csv")
except IOError:
    print("I/O error")
